{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee27e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196939a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a20798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadNpy(filename):\n",
    "    with open(filename, \"rb\") as f: return np.load(f)\n",
    "\n",
    "db = f\"{os.getcwd()}/../data/slices/gaussian-grabber/size160000-hw40-d100/\"\n",
    "data_type = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e26cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = loadNpy(db + f\"X_train.npy\"), loadNpy(db + f\"X_val.npy\"), loadNpy(db + f\"X_test.npy\")\n",
    "y_train, y_val, y_test = loadNpy(db + f\"c-y{data_type}_train.npy\"), loadNpy(db + f\"c-y{data_type}_val.npy\"), loadNpy(db + f\"c-y{data_type}_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb3f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npy_to_tensor(data, l=False):\n",
    "    if not l:\n",
    "        data = torch.from_numpy(data).float()\n",
    "    else:\n",
    "        data = torch.from_numpy(data).type(torch.LongTensor)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82979bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = npy_to_tensor(X_train), npy_to_tensor(X_val), npy_to_tensor(X_test)\n",
    "y_train, y_val, y_test = npy_to_tensor(y_train, 1), npy_to_tensor(y_val, 1), npy_to_tensor(y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e89162",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b11393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Data loader\n",
    "train_iterator = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "val_iterator = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_iterator = DataLoader(dataset=test_dataset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a33e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1200, 160000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8b937da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15444444444444444"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f4c4e6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18666666666666668"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b1733e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15666666666666668"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655068b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e3c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 160000\n",
    "h1_size = 1000\n",
    "h2_size = 100\n",
    "\n",
    "h3_size = 100\n",
    "h4_size = 100\n",
    "h5_size = 100\n",
    "num_classes = 2\n",
    "num_epochs = 1000\n",
    "batch_size = 64\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69619a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1ca0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, h1_size).to(device)\n",
    "        self.bn1 = nn.BatchNorm1d(h1_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.fc2 = nn.Linear(h1_size, h2_size).to(device)\n",
    "        self.bn2 = nn.BatchNorm1d(h2_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \"\"\"\n",
    "        #self.drop1 = nn.Dropout(p=0.1)\n",
    "        #self.bn2 = nn.BatchNorm1d(h2_size)\n",
    "        self.fc3 = nn.Linear(h2_size, h3_size).to(device)\n",
    "        self.bn3 = nn.BatchNorm1d(h3_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.drop3 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        #self.bn3 = nn.BatchNorm1d(h3_size)\n",
    "        self.fc4 = nn.Linear(h3_size, h4_size).to(device)\n",
    "        self.bn4 = nn.BatchNorm1d(h4_size)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.drop4 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        #self.bn4 = nn.BatchNorm1d(h4_size)\n",
    "        #self.drop2 = nn.Dropout(p=0.1)\n",
    "        self.fc5 = nn.Linear(h4_size, h5_size).to(device)\n",
    "        self.bn5 = nn.BatchNorm1d(h4_size)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.drop5 = nn.Dropout(p=0.1)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.fc3 = nn.Linear(h2_size, num_classes).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.drop1(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.drop2(out)\n",
    "        \n",
    "        \"\"\"\n",
    "        #out = self.bn2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        #out = self.bn3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.bn4(out)\n",
    "        out = self.relu4(out)\n",
    "        #out = self.bn4(out)\n",
    "        out = self.fc5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.fc6(out)\n",
    "        \"\"\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd2b83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_nn(mod, data):\n",
    "    preds = []\n",
    "    actual = []\n",
    "    \n",
    "    shape = data.dataset.tensors[0].shape[1:]\n",
    "    \n",
    "    mod.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in data:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = mod(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            preds.append(predicted)\n",
    "            actual.append(labels)\n",
    "\n",
    "        print(f'Accuracy of the network on the {total} test images: {100 * correct / total} %')\n",
    "    return preds, actual, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5307e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NeuralNet(input_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "474699ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d7dccdac9a42199ed67bc72e0554e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [4/12], Loss: 4.7149\n",
      "Accuracy of the network on the 400 test images: 0.0 %\n",
      "Accuracy of the network on the 400 test images: 0.0 %\n",
      "Accuracy of the network on the 1200 test images: 0.0 %\n",
      "Epoch [2/1000], Step [4/12], Loss: 4.5489\n",
      "Accuracy of the network on the 400 test images: 0.0 %\n",
      "Accuracy of the network on the 400 test images: 0.0 %\n",
      "Accuracy of the network on the 1200 test images: 0.08333333333333333 %\n",
      "Epoch [3/1000], Step [4/12], Loss: 4.4231\n",
      "Accuracy of the network on the 400 test images: 1.75 %\n",
      "Accuracy of the network on the 400 test images: 1.5 %\n",
      "Accuracy of the network on the 1200 test images: 1.4166666666666667 %\n",
      "Epoch [4/1000], Step [4/12], Loss: 4.3895\n",
      "Accuracy of the network on the 400 test images: 8.25 %\n",
      "Accuracy of the network on the 400 test images: 6.0 %\n",
      "Accuracy of the network on the 1200 test images: 8.166666666666666 %\n",
      "Epoch [5/1000], Step [4/12], Loss: 4.1643\n",
      "Accuracy of the network on the 400 test images: 18.5 %\n",
      "Accuracy of the network on the 400 test images: 13.5 %\n",
      "Accuracy of the network on the 1200 test images: 17.5 %\n",
      "Epoch [6/1000], Step [4/12], Loss: 4.1250\n",
      "Accuracy of the network on the 400 test images: 30.75 %\n",
      "Accuracy of the network on the 400 test images: 26.75 %\n",
      "Accuracy of the network on the 1200 test images: 27.166666666666668 %\n",
      "Epoch [7/1000], Step [4/12], Loss: 3.9410\n",
      "Accuracy of the network on the 400 test images: 45.5 %\n",
      "Accuracy of the network on the 400 test images: 39.75 %\n",
      "Accuracy of the network on the 1200 test images: 37.5 %\n",
      "Epoch [8/1000], Step [4/12], Loss: 3.8711\n",
      "Accuracy of the network on the 400 test images: 52.5 %\n",
      "Accuracy of the network on the 400 test images: 48.0 %\n",
      "Accuracy of the network on the 1200 test images: 43.75 %\n",
      "Epoch [9/1000], Step [4/12], Loss: 3.8202\n",
      "Accuracy of the network on the 400 test images: 58.25 %\n",
      "Accuracy of the network on the 400 test images: 50.75 %\n",
      "Accuracy of the network on the 1200 test images: 48.75 %\n",
      "Epoch [10/1000], Step [4/12], Loss: 3.6648\n",
      "Accuracy of the network on the 400 test images: 62.5 %\n",
      "Accuracy of the network on the 400 test images: 55.0 %\n",
      "Accuracy of the network on the 1200 test images: 52.416666666666664 %\n",
      "Epoch [11/1000], Step [4/12], Loss: 3.5931\n",
      "Accuracy of the network on the 400 test images: 68.75 %\n",
      "Accuracy of the network on the 400 test images: 64.25 %\n",
      "Accuracy of the network on the 1200 test images: 58.416666666666664 %\n",
      "Epoch [12/1000], Step [4/12], Loss: 3.4442\n",
      "Accuracy of the network on the 400 test images: 73.25 %\n",
      "Accuracy of the network on the 400 test images: 71.0 %\n",
      "Accuracy of the network on the 1200 test images: 65.91666666666667 %\n",
      "Epoch [13/1000], Step [4/12], Loss: 3.3332\n",
      "Accuracy of the network on the 400 test images: 79.75 %\n",
      "Accuracy of the network on the 400 test images: 74.25 %\n",
      "Accuracy of the network on the 1200 test images: 71.08333333333333 %\n",
      "Epoch [14/1000], Step [4/12], Loss: 3.4236\n",
      "Accuracy of the network on the 400 test images: 82.25 %\n",
      "Accuracy of the network on the 400 test images: 72.75 %\n",
      "Accuracy of the network on the 1200 test images: 70.16666666666667 %\n",
      "Epoch [15/1000], Step [4/12], Loss: 3.0735\n",
      "Accuracy of the network on the 400 test images: 77.75 %\n",
      "Accuracy of the network on the 400 test images: 66.75 %\n",
      "Accuracy of the network on the 1200 test images: 62.75 %\n",
      "Epoch [16/1000], Step [4/12], Loss: 3.1029\n",
      "Accuracy of the network on the 400 test images: 78.25 %\n",
      "Accuracy of the network on the 400 test images: 64.75 %\n",
      "Accuracy of the network on the 1200 test images: 57.75 %\n",
      "Epoch [17/1000], Step [4/12], Loss: 2.9624\n",
      "Accuracy of the network on the 400 test images: 83.75 %\n",
      "Accuracy of the network on the 400 test images: 67.5 %\n",
      "Accuracy of the network on the 1200 test images: 61.666666666666664 %\n",
      "Epoch [18/1000], Step [4/12], Loss: 2.9713\n",
      "Accuracy of the network on the 400 test images: 93.0 %\n",
      "Accuracy of the network on the 400 test images: 76.5 %\n",
      "Accuracy of the network on the 1200 test images: 74.41666666666667 %\n",
      "Epoch [19/1000], Step [4/12], Loss: 2.7339\n",
      "Accuracy of the network on the 400 test images: 87.25 %\n",
      "Accuracy of the network on the 400 test images: 72.5 %\n",
      "Accuracy of the network on the 1200 test images: 68.0 %\n",
      "Epoch [20/1000], Step [4/12], Loss: 2.7668\n",
      "Accuracy of the network on the 400 test images: 79.25 %\n",
      "Accuracy of the network on the 400 test images: 64.25 %\n",
      "Accuracy of the network on the 1200 test images: 58.833333333333336 %\n",
      "Epoch [21/1000], Step [4/12], Loss: 2.7749\n",
      "Accuracy of the network on the 400 test images: 78.25 %\n",
      "Accuracy of the network on the 400 test images: 62.0 %\n",
      "Accuracy of the network on the 1200 test images: 56.166666666666664 %\n",
      "Epoch [22/1000], Step [4/12], Loss: 2.8633\n",
      "Accuracy of the network on the 400 test images: 88.25 %\n",
      "Accuracy of the network on the 400 test images: 69.5 %\n",
      "Accuracy of the network on the 1200 test images: 65.91666666666667 %\n",
      "Epoch [23/1000], Step [4/12], Loss: 2.5598\n",
      "Accuracy of the network on the 400 test images: 87.75 %\n",
      "Accuracy of the network on the 400 test images: 70.25 %\n",
      "Accuracy of the network on the 1200 test images: 66.08333333333333 %\n",
      "Epoch [24/1000], Step [4/12], Loss: 2.5387\n",
      "Accuracy of the network on the 400 test images: 83.25 %\n",
      "Accuracy of the network on the 400 test images: 67.25 %\n",
      "Accuracy of the network on the 1200 test images: 61.25 %\n",
      "Epoch [25/1000], Step [4/12], Loss: 2.5374\n",
      "Accuracy of the network on the 400 test images: 87.25 %\n",
      "Accuracy of the network on the 400 test images: 66.75 %\n",
      "Accuracy of the network on the 1200 test images: 64.58333333333333 %\n",
      "Epoch [26/1000], Step [4/12], Loss: 2.7287\n",
      "Accuracy of the network on the 400 test images: 81.25 %\n",
      "Accuracy of the network on the 400 test images: 59.75 %\n",
      "Accuracy of the network on the 1200 test images: 56.5 %\n",
      "Epoch [27/1000], Step [4/12], Loss: 2.3668\n",
      "Accuracy of the network on the 400 test images: 89.5 %\n",
      "Accuracy of the network on the 400 test images: 70.5 %\n",
      "Accuracy of the network on the 1200 test images: 66.25 %\n",
      "Epoch [28/1000], Step [4/12], Loss: 2.4259\n",
      "Accuracy of the network on the 400 test images: 86.0 %\n",
      "Accuracy of the network on the 400 test images: 68.0 %\n",
      "Accuracy of the network on the 1200 test images: 63.333333333333336 %\n",
      "Epoch [29/1000], Step [4/12], Loss: 2.3290\n",
      "Accuracy of the network on the 400 test images: 84.75 %\n",
      "Accuracy of the network on the 400 test images: 66.0 %\n",
      "Accuracy of the network on the 1200 test images: 60.75 %\n",
      "Epoch [30/1000], Step [4/12], Loss: 2.3943\n",
      "Accuracy of the network on the 400 test images: 85.75 %\n",
      "Accuracy of the network on the 400 test images: 67.75 %\n",
      "Accuracy of the network on the 1200 test images: 65.33333333333333 %\n",
      "Epoch [31/1000], Step [4/12], Loss: 2.2877\n",
      "Accuracy of the network on the 400 test images: 83.0 %\n",
      "Accuracy of the network on the 400 test images: 67.25 %\n",
      "Accuracy of the network on the 1200 test images: 62.416666666666664 %\n",
      "Epoch [32/1000], Step [4/12], Loss: 2.1034\n",
      "Accuracy of the network on the 400 test images: 88.5 %\n",
      "Accuracy of the network on the 400 test images: 71.75 %\n",
      "Accuracy of the network on the 1200 test images: 69.33333333333333 %\n",
      "Epoch [33/1000], Step [4/12], Loss: 2.1210\n",
      "Accuracy of the network on the 400 test images: 87.5 %\n",
      "Accuracy of the network on the 400 test images: 71.25 %\n",
      "Accuracy of the network on the 1200 test images: 68.33333333333333 %\n",
      "Epoch [34/1000], Step [4/12], Loss: 2.0911\n",
      "Accuracy of the network on the 400 test images: 84.0 %\n",
      "Accuracy of the network on the 400 test images: 65.25 %\n",
      "Accuracy of the network on the 1200 test images: 61.916666666666664 %\n",
      "Epoch [35/1000], Step [4/12], Loss: 2.0636\n",
      "Accuracy of the network on the 400 test images: 86.5 %\n",
      "Accuracy of the network on the 400 test images: 65.5 %\n",
      "Accuracy of the network on the 1200 test images: 62.583333333333336 %\n",
      "Epoch [36/1000], Step [4/12], Loss: 2.0214\n",
      "Accuracy of the network on the 400 test images: 84.5 %\n",
      "Accuracy of the network on the 400 test images: 66.75 %\n",
      "Accuracy of the network on the 1200 test images: 63.583333333333336 %\n",
      "Epoch [37/1000], Step [4/12], Loss: 2.0482\n",
      "Accuracy of the network on the 400 test images: 89.75 %\n",
      "Accuracy of the network on the 400 test images: 73.25 %\n",
      "Accuracy of the network on the 1200 test images: 68.33333333333333 %\n",
      "Epoch [38/1000], Step [4/12], Loss: 1.8834\n",
      "Accuracy of the network on the 400 test images: 90.0 %\n",
      "Accuracy of the network on the 400 test images: 71.75 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1200 test images: 66.75 %\n",
      "Epoch [39/1000], Step [4/12], Loss: 1.8683\n",
      "Accuracy of the network on the 400 test images: 89.5 %\n",
      "Accuracy of the network on the 400 test images: 72.25 %\n",
      "Accuracy of the network on the 1200 test images: 67.41666666666667 %\n",
      "Epoch [40/1000], Step [4/12], Loss: 1.7797\n",
      "Accuracy of the network on the 400 test images: 89.5 %\n",
      "Accuracy of the network on the 400 test images: 73.25 %\n",
      "Accuracy of the network on the 1200 test images: 69.0 %\n",
      "Epoch [41/1000], Step [4/12], Loss: 2.0309\n",
      "Accuracy of the network on the 400 test images: 92.75 %\n",
      "Accuracy of the network on the 400 test images: 72.5 %\n",
      "Accuracy of the network on the 1200 test images: 71.25 %\n",
      "Epoch [42/1000], Step [4/12], Loss: 2.1378\n",
      "Accuracy of the network on the 400 test images: 88.25 %\n",
      "Accuracy of the network on the 400 test images: 72.0 %\n",
      "Accuracy of the network on the 1200 test images: 68.58333333333333 %\n",
      "Epoch [43/1000], Step [4/12], Loss: 1.8479\n",
      "Accuracy of the network on the 400 test images: 82.75 %\n",
      "Accuracy of the network on the 400 test images: 68.25 %\n",
      "Accuracy of the network on the 1200 test images: 63.583333333333336 %\n",
      "Epoch [44/1000], Step [4/12], Loss: 1.9241\n",
      "Accuracy of the network on the 400 test images: 83.25 %\n",
      "Accuracy of the network on the 400 test images: 66.5 %\n",
      "Accuracy of the network on the 1200 test images: 63.5 %\n",
      "Epoch [45/1000], Step [4/12], Loss: 1.8790\n",
      "Accuracy of the network on the 400 test images: 85.0 %\n",
      "Accuracy of the network on the 400 test images: 69.25 %\n",
      "Accuracy of the network on the 1200 test images: 66.83333333333333 %\n",
      "Epoch [46/1000], Step [4/12], Loss: 1.7754\n",
      "Accuracy of the network on the 400 test images: 84.5 %\n",
      "Accuracy of the network on the 400 test images: 71.0 %\n",
      "Accuracy of the network on the 1200 test images: 66.08333333333333 %\n",
      "Epoch [47/1000], Step [4/12], Loss: 2.0065\n",
      "Accuracy of the network on the 400 test images: 87.0 %\n",
      "Accuracy of the network on the 400 test images: 72.0 %\n",
      "Accuracy of the network on the 1200 test images: 68.66666666666667 %\n",
      "Epoch [48/1000], Step [4/12], Loss: 1.6533\n",
      "Accuracy of the network on the 400 test images: 89.25 %\n",
      "Accuracy of the network on the 400 test images: 73.0 %\n",
      "Accuracy of the network on the 1200 test images: 72.0 %\n",
      "Epoch [49/1000], Step [4/12], Loss: 1.6477\n",
      "Accuracy of the network on the 400 test images: 90.0 %\n",
      "Accuracy of the network on the 400 test images: 73.25 %\n",
      "Accuracy of the network on the 1200 test images: 72.25 %\n",
      "Epoch [50/1000], Step [4/12], Loss: 1.6775\n",
      "Accuracy of the network on the 400 test images: 88.5 %\n",
      "Accuracy of the network on the 400 test images: 71.0 %\n",
      "Accuracy of the network on the 1200 test images: 67.58333333333333 %\n",
      "Epoch [51/1000], Step [4/12], Loss: 1.5369\n",
      "Accuracy of the network on the 400 test images: 87.25 %\n",
      "Accuracy of the network on the 400 test images: 71.5 %\n",
      "Accuracy of the network on the 1200 test images: 67.0 %\n",
      "Epoch [52/1000], Step [4/12], Loss: 1.7551\n",
      "Accuracy of the network on the 400 test images: 87.25 %\n",
      "Accuracy of the network on the 400 test images: 73.0 %\n",
      "Accuracy of the network on the 1200 test images: 70.66666666666667 %\n",
      "Epoch [53/1000], Step [4/12], Loss: 1.8642\n",
      "Accuracy of the network on the 400 test images: 92.5 %\n",
      "Accuracy of the network on the 400 test images: 76.0 %\n",
      "Accuracy of the network on the 1200 test images: 74.41666666666667 %\n",
      "Epoch [54/1000], Step [4/12], Loss: 1.4721\n",
      "Accuracy of the network on the 400 test images: 90.25 %\n",
      "Accuracy of the network on the 400 test images: 74.25 %\n",
      "Accuracy of the network on the 1200 test images: 73.08333333333333 %\n",
      "Epoch [55/1000], Step [4/12], Loss: 1.7228\n",
      "Accuracy of the network on the 400 test images: 87.0 %\n",
      "Accuracy of the network on the 400 test images: 72.75 %\n",
      "Accuracy of the network on the 1200 test images: 67.58333333333333 %\n",
      "Epoch [56/1000], Step [4/12], Loss: 1.4951\n",
      "Accuracy of the network on the 400 test images: 91.0 %\n",
      "Accuracy of the network on the 400 test images: 76.5 %\n",
      "Accuracy of the network on the 1200 test images: 73.83333333333333 %\n",
      "Epoch [57/1000], Step [4/12], Loss: 1.8724\n",
      "Accuracy of the network on the 400 test images: 84.0 %\n",
      "Accuracy of the network on the 400 test images: 70.5 %\n",
      "Accuracy of the network on the 1200 test images: 67.0 %\n",
      "Epoch [58/1000], Step [4/12], Loss: 1.6050\n",
      "Accuracy of the network on the 400 test images: 84.25 %\n",
      "Accuracy of the network on the 400 test images: 69.5 %\n",
      "Accuracy of the network on the 1200 test images: 66.58333333333333 %\n",
      "Epoch [59/1000], Step [4/12], Loss: 1.4875\n",
      "Accuracy of the network on the 400 test images: 91.25 %\n",
      "Accuracy of the network on the 400 test images: 72.0 %\n",
      "Accuracy of the network on the 1200 test images: 71.5 %\n",
      "Epoch [60/1000], Step [4/12], Loss: 1.7176\n",
      "Accuracy of the network on the 400 test images: 87.25 %\n",
      "Accuracy of the network on the 400 test images: 70.75 %\n",
      "Accuracy of the network on the 1200 test images: 67.41666666666667 %\n",
      "Epoch [61/1000], Step [4/12], Loss: 1.4422\n",
      "Accuracy of the network on the 400 test images: 86.75 %\n",
      "Accuracy of the network on the 400 test images: 72.5 %\n",
      "Accuracy of the network on the 1200 test images: 68.5 %\n",
      "Epoch [62/1000], Step [4/12], Loss: 1.8576\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48386/3748980511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n\u001b[1;32m     24\u001b[0m            .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n\u001b[0;32m---> 25\u001b[0;31m     nn_epochs[epoch] = {\"loss\": loss.item(), \"train\": eval_nn(nn_model, test_iterator), \n\u001b[0m\u001b[1;32m     26\u001b[0m                  \"val\": eval_nn(nn_model, val_iterator), \"test\": eval_nn(nn_model, train_iterator)}\n\u001b[1;32m     27\u001b[0m     \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48386/3169449419.py\u001b[0m in \u001b[0;36meval_nn\u001b[0;34m(mod, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn_epochs = {}\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_iterator)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for i, (images, labels) in enumerate(test_iterator):  \n",
    "        # Move tensors to the configured device\n",
    "        #print(images.shape)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        #print(images.shape)\n",
    "        outputs = nn_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(i)\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "    nn_epochs[epoch] = {\"loss\": loss.item(), \"train\": eval_nn(nn_model, train_iterator), \n",
    "                 \"val\": eval_nn(nn_model, val_iterator), \"test\": eval_nn(nn_model, test_iterator)}\n",
    "    nn_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94228bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_nn(nn_model, val_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffe76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e86ba484",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train': train_iterator,\n",
    "    'val': val_iterator,\n",
    "    'test': test_iterator\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5aa612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=40,              \n",
    "                out_channels=64,            \n",
    "                kernel_size=8,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        ).to(device)\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(64, 64, 5, 1, 2),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.1),\n",
    "            nn.MaxPool2d(2),                \n",
    "        ).to(device)\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(64, 256, 5, 1, 2),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.1),\n",
    "            #nn.MaxPool2d(3),\n",
    "        ).to(device)\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.1),\n",
    "            #nn.MaxPool2d(2),\n",
    "        ).to(device)\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 512, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.1)\n",
    "        ).to(device)\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "        self.conv8 = nn.Sequential(         \n",
    "            nn.Conv2d(256, 128, 5, 1, 2),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.1),\n",
    "            #nn.MaxPool2d(2),                \n",
    "        ).to(device)\n",
    "        self.conv9 = nn.Sequential(         \n",
    "            nn.Conv2d(128, 512, 5, 1, 2),\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.1),\n",
    "            #nn.MaxPool2d(3),\n",
    "        ).to(device)\n",
    "        self.conv10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 128, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(p=0.1),\n",
    "            #nn.MaxPool2d(2),\n",
    "        ).to(device)\n",
    "        self.conv11 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "        \n",
    "        \n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(64*12*12, 2).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.conv11(x)\n",
    "        \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebb94006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ROC\n",
    "\n",
    "def eval_cnn(data):\n",
    "    \n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        pred_ys = []\n",
    "        labs = []\n",
    "        for images, labels in loaders[data]:\n",
    "            images = images.reshape(-1,54,54,54).to(device)\n",
    "            labels = labels.to(device)\n",
    "            test_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            pred_ys = pred_ys + test_output.flatten().tolist()\n",
    "            labs = labs + labels.tolist()\n",
    "            total += len(labels)\n",
    "            correct += (pred_y == labels).sum().item()\n",
    "            pass\n",
    "        print(f'{data} Accuracy of the model on the {total} {data} images: %.3f' % (correct/total))\n",
    "        return pred_ys, labs, correct/total\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c45a8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(54, 64, kernel_size=(8, 8), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv2d(128, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv7): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv8): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv9): Sequential(\n",
      "    (0): Conv2d(128, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv10): Sequential(\n",
      "    (0): Conv2d(512, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv11): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Linear(in_features=9216, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bc4574e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()   \n",
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15000d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.001)   \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32718eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d183acec29a941718213b7898b45b70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [1/6], Loss: 0.6963\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [2/1000], Step [1/6], Loss: 0.6697\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [3/1000], Step [1/6], Loss: 0.6357\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [4/1000], Step [1/6], Loss: 0.6504\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.869\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [5/1000], Step [1/6], Loss: 0.6324\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [6/1000], Step [1/6], Loss: 0.5333\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [7/1000], Step [1/6], Loss: 0.4702\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [8/1000], Step [1/6], Loss: 0.4585\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [9/1000], Step [1/6], Loss: 0.4360\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [10/1000], Step [1/6], Loss: 0.4335\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [11/1000], Step [1/6], Loss: 0.4343\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [12/1000], Step [1/6], Loss: 0.4302\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [13/1000], Step [1/6], Loss: 0.4295\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [14/1000], Step [1/6], Loss: 0.4281\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [15/1000], Step [1/6], Loss: 0.4260\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [16/1000], Step [1/6], Loss: 0.4269\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [17/1000], Step [1/6], Loss: 0.4248\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [18/1000], Step [1/6], Loss: 0.4245\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [19/1000], Step [1/6], Loss: 0.4248\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [20/1000], Step [1/6], Loss: 0.4241\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [21/1000], Step [1/6], Loss: 0.4240\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [22/1000], Step [1/6], Loss: 0.4243\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [23/1000], Step [1/6], Loss: 0.4241\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [24/1000], Step [1/6], Loss: 0.4243\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [25/1000], Step [1/6], Loss: 0.4240\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [26/1000], Step [1/6], Loss: 0.4251\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [27/1000], Step [1/6], Loss: 0.4383\n",
      "train Accuracy of the model on the 480 train images: 0.140\n",
      "val Accuracy of the model on the 160 val images: 0.119\n",
      "test Accuracy of the model on the 160 test images: 0.188\n",
      "Epoch [28/1000], Step [1/6], Loss: 0.4255\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [29/1000], Step [1/6], Loss: 0.4254\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [30/1000], Step [1/6], Loss: 0.4228\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [31/1000], Step [1/6], Loss: 0.4267\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [32/1000], Step [1/6], Loss: 0.4251\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [33/1000], Step [1/6], Loss: 0.4232\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n",
      "Epoch [34/1000], Step [1/6], Loss: 0.4232\n",
      "train Accuracy of the model on the 480 train images: 0.863\n",
      "val Accuracy of the model on the 160 val images: 0.875\n",
      "test Accuracy of the model on the 160 test images: 0.812\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42092/821039781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_42092/821039781.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, cnn, loaders)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m54\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m54\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m54\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# gives batch data, normalize x when iterate train_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "num_epochs = 1000\n",
    "cnn_epochs = {}\n",
    "\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    \n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            images = images.reshape(-1,54,54,54).to(device)\n",
    "            labels = labels.to(device)\n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            output = cnn(b_x)[0]               \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            #print(i)\n",
    "            if (i) % 10 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "                cnn_epochs[epoch] = {\"loss\": loss.item(), \"train\": eval_cnn(\"train\"), \n",
    "                             \"val\": eval_cnn(\"val\"), \"test\": eval_cnn(\"test\")}\n",
    "                cnn.train()\n",
    "                pass\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4cf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
